{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from strategy import *\n",
    "from learner import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Loading and visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def print_shapes(*args, **kwargs):\n",
    "    for i in args:\n",
    "        print(i.shape)\n",
    "    for i in kwargs.keys():\n",
    "        print(kwargs[i].shape)\n",
    "\n",
    "def print_all(*args, **kwargs):\n",
    "    for i in args:\n",
    "        print(i)\n",
    "    for i in kwargs.keys():\n",
    "        print(kwargs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "data = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "(1797,)\n",
      "(10,)\n",
      "(1797, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "print_shapes(data['data'], data['target'], data['target_names'], data['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a13da6c50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data['data'][np.random.randint(0, 1000)].reshape(8,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Splitting the data|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "X, y = data['data'], data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X, y, \n",
    "                                                  test_size=0.1, random_state=42, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1617, 64)\n",
      "(180, 64)\n",
      "(1617,)\n",
      "(180,)\n"
     ]
    }
   ],
   "source": [
    "print_shapes(x_train, x_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Now splitting into labelled and unlabelled data for purposes of active learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "x_labelled, x_unlabelled, y_labelled, y_unlabelled = train_test_split(\n",
    "                                                    x_train, y_train, test_size=0.99, random_state=42, stratify=y_train)\n",
    "\n",
    "x = object()\n",
    "y = object()\n",
    "\n",
    "train = {x: x_labelled, y: y_labelled}\n",
    "stream = {x: x_unlabelled, y: y_unlabelled}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Making the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Uncertainty sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stream_list = [(stream[x][i][None, :], stream[y][i][None]) for i in range(stream[x].shape[0])]\n",
    "\n",
    "model = [RandomForestClassifier()]\n",
    "strategy = uncertainty_sampling\n",
    "stream_iter = iter(stream_list)\n",
    "\n",
    "learner = ActiveLearner(model, strategy='uncertainity', uncertainity_measure='lc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akash/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "learner.teach(train[x], train[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39444444444444443"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.score(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\t Score: 0.39444444444444443\n",
      "Iteration: 5\t Score: 0.4666666666666667\n",
      "Iteration: 10\t Score: 0.43333333333333335\n",
      "Iteration: 15\t Score: 0.4111111111111111\n",
      "Iteration: 20\t Score: 0.5166666666666667\n",
      "Iteration: 25\t Score: 0.5722222222222222\n",
      "Iteration: 30\t Score: 0.6\n",
      "Iteration: 35\t Score: 0.5555555555555556\n",
      "Iteration: 40\t Score: 0.5888888888888889\n",
      "Iteration: 45\t Score: 0.6611111111111111\n",
      "Iteration: 50\t Score: 0.6388888888888888\n",
      "Iteration: 55\t Score: 0.5944444444444444\n",
      "Iteration: 60\t Score: 0.6833333333333333\n",
      "Iteration: 65\t Score: 0.6111111111111112\n",
      "Iteration: 70\t Score: 0.6666666666666666\n",
      "Iteration: 75\t Score: 0.7166666666666667\n",
      "Iteration: 80\t Score: 0.7166666666666667\n",
      "Iteration: 85\t Score: 0.7222222222222222\n",
      "Iteration: 90\t Score: 0.75\n",
      "Iteration: 95\t Score: 0.7944444444444444\n",
      "Iteration: 100\t Score: 0.7555555555555555\n",
      "Iteration: 105\t Score: 0.7055555555555556\n",
      "Iteration: 110\t Score: 0.6777777777777778\n",
      "Iteration: 115\t Score: 0.7722222222222223\n",
      "Iteration: 120\t Score: 0.7111111111111111\n",
      "Iteration: 125\t Score: 0.8\n",
      "Iteration: 130\t Score: 0.7388888888888889\n",
      "Iteration: 135\t Score: 0.7722222222222223\n",
      "Iteration: 140\t Score: 0.7555555555555555\n",
      "Iteration: 145\t Score: 0.7888888888888889\n",
      "Iteration: 150\t Score: 0.7444444444444445\n",
      "Iteration: 155\t Score: 0.7722222222222223\n",
      "Iteration: 160\t Score: 0.8333333333333334\n",
      "Iteration: 165\t Score: 0.7722222222222223\n",
      "Iteration: 170\t Score: 0.7833333333333333\n",
      "Iteration: 175\t Score: 0.8277777777777777\n",
      "Iteration: 180\t Score: 0.8722222222222222\n",
      "Iteration: 185\t Score: 0.8555555555555555\n",
      "Iteration: 190\t Score: 0.8277777777777777\n",
      "Iteration: 195\t Score: 0.7944444444444444\n",
      "Iteration: 200\t Score: 0.8444444444444444\n",
      "Iteration: 205\t Score: 0.8555555555555555\n",
      "Iteration: 210\t Score: 0.8333333333333334\n",
      "Iteration: 215\t Score: 0.85\n",
      "Iteration: 220\t Score: 0.85\n",
      "Iteration: 225\t Score: 0.8055555555555556\n",
      "Iteration: 230\t Score: 0.8555555555555555\n",
      "Iteration: 235\t Score: 0.8555555555555555\n",
      "Iteration: 240\t Score: 0.8111111111111111\n",
      "Iteration: 245\t Score: 0.8111111111111111\n",
      "Iteration: 250\t Score: 0.85\n",
      "Iteration: 255\t Score: 0.8222222222222222\n",
      "Iteration: 260\t Score: 0.8444444444444444\n",
      "Iteration: 265\t Score: 0.8166666666666667\n",
      "Iteration: 270\t Score: 0.8444444444444444\n",
      "Iteration: 275\t Score: 0.8222222222222222\n",
      "Iteration: 280\t Score: 0.8722222222222222\n",
      "Iteration: 285\t Score: 0.8388888888888889\n",
      "Iteration: 290\t Score: 0.8666666666666667\n",
      "Iteration: 295\t Score: 0.8277777777777777\n",
      "Iteration: 300\t Score: 0.8\n",
      "Iteration: 305\t Score: 0.8555555555555555\n",
      "Iteration: 310\t Score: 0.8555555555555555\n",
      "Iteration: 315\t Score: 0.8888888888888888\n",
      "Iteration: 320\t Score: 0.85\n",
      "Iteration: 325\t Score: 0.85\n",
      "Iteration: 330\t Score: 0.9\n",
      "Iteration: 335\t Score: 0.8666666666666667\n",
      "Iteration: 340\t Score: 0.8833333333333333\n",
      "Iteration: 345\t Score: 0.8777777777777778\n",
      "Iteration: 350\t Score: 0.8611111111111112\n",
      "Iteration: 355\t Score: 0.8611111111111112\n",
      "Iteration: 360\t Score: 0.8611111111111112\n",
      "Iteration: 365\t Score: 0.8777777777777778\n",
      "Iteration: 370\t Score: 0.8777777777777778\n",
      "Iteration: 375\t Score: 0.8777777777777778\n",
      "Iteration: 380\t Score: 0.8777777777777778\n",
      "Iteration: 385\t Score: 0.8777777777777778\n",
      "Iteration: 390\t Score: 0.8888888888888888\n",
      "Iteration: 395\t Score: 0.8888888888888888\n",
      "Iteration: 400\t Score: 0.8666666666666667\n",
      "Iteration: 405\t Score: 0.8722222222222222\n",
      "Iteration: 410\t Score: 0.8777777777777778\n",
      "Iteration: 415\t Score: 0.8777777777777778\n",
      "Iteration: 420\t Score: 0.8888888888888888\n",
      "Iteration: 425\t Score: 0.8555555555555555\n",
      "Iteration: 430\t Score: 0.8611111111111112\n",
      "Iteration: 435\t Score: 0.8388888888888889\n",
      "Iteration: 440\t Score: 0.8722222222222222\n",
      "Iteration: 445\t Score: 0.8555555555555555\n",
      "Iteration: 450\t Score: 0.8722222222222222\n",
      "Iteration: 455\t Score: 0.8777777777777778\n",
      "Iteration: 460\t Score: 0.8944444444444445\n",
      "Iteration: 465\t Score: 0.8944444444444445\n",
      "Iteration: 470\t Score: 0.9\n",
      "Iteration: 475\t Score: 0.8666666666666667\n",
      "Iteration: 480\t Score: 0.9222222222222223\n",
      "Iteration: 485\t Score: 0.8666666666666667\n",
      "Iteration: 490\t Score: 0.8777777777777778\n",
      "Iteration: 495\t Score: 0.9222222222222223\n",
      "Iteration: 500\t Score: 0.9166666666666666\n",
      "Iteration: 505\t Score: 0.8777777777777778\n",
      "Iteration: 510\t Score: 0.9111111111111111\n",
      "Iteration: 515\t Score: 0.9166666666666666\n",
      "Iteration: 520\t Score: 0.8722222222222222\n",
      "Iteration: 525\t Score: 0.8944444444444445\n",
      "Iteration: 530\t Score: 0.9\n",
      "Iteration: 535\t Score: 0.9166666666666666\n",
      "Iteration: 540\t Score: 0.8888888888888888\n",
      "Iteration: 545\t Score: 0.8388888888888889\n",
      "Iteration: 550\t Score: 0.9055555555555556\n",
      "Iteration: 555\t Score: 0.9055555555555556\n",
      "Iteration: 560\t Score: 0.9111111111111111\n",
      "Iteration: 565\t Score: 0.9111111111111111\n",
      "Iteration: 570\t Score: 0.8833333333333333\n",
      "Iteration: 575\t Score: 0.8777777777777778\n",
      "Iteration: 580\t Score: 0.9\n",
      "Iteration: 585\t Score: 0.9\n",
      "Iteration: 590\t Score: 0.9055555555555556\n",
      "Iteration: 595\t Score: 0.8611111111111112\n",
      "Iteration: 600\t Score: 0.8944444444444445\n",
      "Iteration: 605\t Score: 0.9277777777777778\n",
      "Iteration: 610\t Score: 0.8888888888888888\n",
      "Iteration: 615\t Score: 0.8888888888888888\n",
      "Iteration: 620\t Score: 0.9\n",
      "Iteration: 625\t Score: 0.9055555555555556\n",
      "Iteration: 630\t Score: 0.9111111111111111\n",
      "Iteration: 635\t Score: 0.8944444444444445\n",
      "Iteration: 640\t Score: 0.8944444444444445\n",
      "Iteration: 645\t Score: 0.8944444444444445\n",
      "Iteration: 650\t Score: 0.9055555555555556\n",
      "Iteration: 655\t Score: 0.9222222222222223\n",
      "Iteration: 660\t Score: 0.8888888888888888\n",
      "Iteration: 665\t Score: 0.8833333333333333\n",
      "Iteration: 670\t Score: 0.9333333333333333\n",
      "Iteration: 675\t Score: 0.9111111111111111\n",
      "Iteration: 680\t Score: 0.8611111111111112\n",
      "Iteration: 685\t Score: 0.9\n",
      "Iteration: 690\t Score: 0.9055555555555556\n",
      "Iteration: 695\t Score: 0.9\n",
      "Iteration: 700\t Score: 0.9\n",
      "Iteration: 705\t Score: 0.9111111111111111\n",
      "Iteration: 710\t Score: 0.8888888888888888\n",
      "Iteration: 715\t Score: 0.8888888888888888\n",
      "Iteration: 720\t Score: 0.8888888888888888\n",
      "Iteration: 725\t Score: 0.9333333333333333\n",
      "Iteration: 730\t Score: 0.9\n",
      "Iteration: 735\t Score: 0.9\n",
      "Iteration: 740\t Score: 0.8777777777777778\n",
      "Iteration: 745\t Score: 0.8722222222222222\n",
      "Iteration: 750\t Score: 0.8888888888888888\n",
      "Iteration: 755\t Score: 0.8666666666666667\n",
      "Iteration: 760\t Score: 0.9166666666666666\n",
      "Iteration: 765\t Score: 0.8888888888888888\n",
      "Iteration: 770\t Score: 0.8944444444444445\n",
      "Iteration: 775\t Score: 0.9111111111111111\n",
      "Iteration: 780\t Score: 0.8611111111111112\n",
      "Iteration: 785\t Score: 0.8666666666666667\n",
      "Iteration: 790\t Score: 0.9222222222222223\n",
      "Iteration: 795\t Score: 0.9055555555555556\n",
      "Iteration: 800\t Score: 0.9\n",
      "Iteration: 805\t Score: 0.9333333333333333\n",
      "Iteration: 810\t Score: 0.9222222222222223\n",
      "Iteration: 815\t Score: 0.9\n",
      "Iteration: 820\t Score: 0.9055555555555556\n",
      "Iteration: 825\t Score: 0.9055555555555556\n",
      "Iteration: 830\t Score: 0.8722222222222222\n",
      "Iteration: 835\t Score: 0.8833333333333333\n",
      "Iteration: 840\t Score: 0.9333333333333333\n",
      "Iteration: 845\t Score: 0.9166666666666666\n",
      "Iteration: 850\t Score: 0.9222222222222223\n",
      "Iteration: 855\t Score: 0.8944444444444445\n",
      "Iteration: 860\t Score: 0.8777777777777778\n",
      "Iteration: 865\t Score: 0.9\n",
      "Iteration: 870\t Score: 0.8722222222222222\n",
      "Iteration: 875\t Score: 0.9333333333333333\n",
      "Iteration: 880\t Score: 0.9333333333333333\n",
      "Iteration: 885\t Score: 0.9055555555555556\n",
      "Iteration: 890\t Score: 0.9055555555555556\n",
      "Iteration: 895\t Score: 0.9111111111111111\n",
      "Iteration: 900\t Score: 0.9388888888888889\n",
      "Iteration: 905\t Score: 0.8888888888888888\n",
      "Iteration: 910\t Score: 0.9166666666666666\n",
      "Iteration: 915\t Score: 0.9333333333333333\n",
      "Iteration: 920\t Score: 0.9055555555555556\n",
      "Iteration: 925\t Score: 0.8888888888888888\n",
      "Iteration: 930\t Score: 0.8888888888888888\n",
      "Iteration: 935\t Score: 0.9388888888888889\n",
      "Iteration: 940\t Score: 0.9\n",
      "Iteration: 945\t Score: 0.9\n",
      "Iteration: 950\t Score: 0.8833333333333333\n",
      "Iteration: 955\t Score: 0.9222222222222223\n",
      "Iteration: 960\t Score: 0.9222222222222223\n",
      "Iteration: 965\t Score: 0.9055555555555556\n",
      "Iteration: 970\t Score: 0.8833333333333333\n",
      "Iteration: 975\t Score: 0.9333333333333333\n",
      "Iteration: 980\t Score: 0.9222222222222223\n",
      "Iteration: 985\t Score: 0.8944444444444445\n",
      "Iteration: 990\t Score: 0.8944444444444445\n",
      "Iteration: 995\t Score: 0.9166666666666666\n",
      "Iteration: 1000\t Score: 0.8722222222222222\n",
      "Iteration: 1005\t Score: 0.9111111111111111\n",
      "Iteration: 1010\t Score: 0.9\n",
      "Iteration: 1015\t Score: 0.9277777777777778\n",
      "Iteration: 1020\t Score: 0.9444444444444444\n",
      "Iteration: 1025\t Score: 0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1030\t Score: 0.9055555555555556\n",
      "Iteration: 1035\t Score: 0.9111111111111111\n",
      "Iteration: 1040\t Score: 0.9277777777777778\n",
      "Iteration: 1045\t Score: 0.9277777777777778\n",
      "Iteration: 1050\t Score: 0.9333333333333333\n",
      "Iteration: 1055\t Score: 0.9333333333333333\n",
      "Iteration: 1060\t Score: 0.8888888888888888\n",
      "Iteration: 1065\t Score: 0.8888888888888888\n",
      "Iteration: 1070\t Score: 0.9055555555555556\n",
      "Iteration: 1075\t Score: 0.8944444444444445\n",
      "Iteration: 1080\t Score: 0.8944444444444445\n",
      "Iteration: 1085\t Score: 0.9055555555555556\n",
      "Iteration: 1090\t Score: 0.8944444444444445\n",
      "Iteration: 1095\t Score: 0.8944444444444445\n",
      "Iteration: 1100\t Score: 0.8944444444444445\n",
      "Iteration: 1105\t Score: 0.9166666666666666\n",
      "Iteration: 1110\t Score: 0.9222222222222223\n",
      "Iteration: 1115\t Score: 0.9277777777777778\n",
      "Iteration: 1120\t Score: 0.9277777777777778\n",
      "Iteration: 1125\t Score: 0.9333333333333333\n",
      "Iteration: 1130\t Score: 0.9333333333333333\n",
      "Iteration: 1135\t Score: 0.9055555555555556\n",
      "FINAL Iteration: 1140\t Score: 0.95\t New Samples Taken: 445\n"
     ]
    }
   ],
   "source": [
    "num_iters = 0\n",
    "num_samples_taken = 0\n",
    "score = learner.score(x_val, y_val)\n",
    "while score < 0.95:\n",
    "    print(f\"Iteration: {num_iters}\\t Score: {score}\")\n",
    "    for i in range(5):\n",
    "        num_iters += 1\n",
    "        inp, target = next(stream_iter)\n",
    "        if learner.query(inp):\n",
    "            num_samples_taken += 1\n",
    "            learner.teach(inp, target)\n",
    "    score = learner.score(x_val, y_val)\n",
    "print(f\"FINAL Iteration: {num_iters}\\t Score: {score}\\t New Samples Taken: {num_samples_taken}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Query by committee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = np.array([[0.6666, 0.3333, 0.0], [0.0, 0.6666, 0.3333], [0.3333, 0.3333, 0.3333],\n",
    "      [0.0   , 0.0   , 1.0   ],\n",
    "      [0.0   , 0.3333, 0.6666]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6666, 0.3333, 0.    ],\n",
       "       [0.    , 0.6666, 0.3333],\n",
       "       [0.3333, 0.3333, 0.3333],\n",
       "       [0.    , 0.    , 1.    ],\n",
       "       [0.    , 0.3333, 0.6666]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.63651417, 0.63651417, 1.09861229, 0.        , 0.63651417])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(a.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33333333, 0.66666667, 0.        ])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([2, 4, 0])\n",
    "a = a / a.sum()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6365141682948128"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Measure : Vote Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "models = [RandomForestClassifier(n_estimators=8), \n",
    "         RandomForestClassifier(n_estimators=12), \n",
    "         RandomForestClassifier(n_estimators=16),\n",
    "         RandomForestClassifier(n_estimators=20),\n",
    "         RandomForestClassifier(n_estimators=24)]\n",
    "strategy = \"committee\"\n",
    "committee_measure = \"vote entropy\"\n",
    "\n",
    "learner = ActiveLearner(models, strategy=strategy, committee_measure=committee_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learner.teach(train[x], train[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49444444444444446"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.score(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\t Score: 0.49444444444444446\n",
      "Iteration: 5\t Score: 0.5222222222222223\n",
      "Iteration: 10\t Score: 0.5\n",
      "Iteration: 15\t Score: 0.4722222222222222\n",
      "Iteration: 20\t Score: 0.5722222222222222\n",
      "Iteration: 25\t Score: 0.6611111111111111\n",
      "Iteration: 30\t Score: 0.6333333333333333\n",
      "Iteration: 35\t Score: 0.6388888888888888\n",
      "Iteration: 40\t Score: 0.6333333333333333\n",
      "Iteration: 45\t Score: 0.7444444444444445\n",
      "Iteration: 50\t Score: 0.7277777777777777\n",
      "Iteration: 55\t Score: 0.7277777777777777\n",
      "Iteration: 60\t Score: 0.7277777777777777\n",
      "Iteration: 65\t Score: 0.7055555555555556\n",
      "Iteration: 70\t Score: 0.7833333333333333\n",
      "Iteration: 75\t Score: 0.6944444444444444\n",
      "Iteration: 80\t Score: 0.7166666666666667\n",
      "Iteration: 85\t Score: 0.7666666666666667\n",
      "Iteration: 90\t Score: 0.7944444444444444\n",
      "Iteration: 95\t Score: 0.8166666666666667\n",
      "Iteration: 100\t Score: 0.8277777777777777\n",
      "Iteration: 105\t Score: 0.8\n",
      "Iteration: 110\t Score: 0.8055555555555556\n",
      "Iteration: 115\t Score: 0.7888888888888889\n",
      "Iteration: 120\t Score: 0.8222222222222222\n",
      "Iteration: 125\t Score: 0.8277777777777777\n",
      "Iteration: 130\t Score: 0.8555555555555555\n",
      "Iteration: 135\t Score: 0.8611111111111112\n",
      "Iteration: 140\t Score: 0.8555555555555555\n",
      "Iteration: 145\t Score: 0.8333333333333334\n",
      "Iteration: 150\t Score: 0.8555555555555555\n",
      "Iteration: 155\t Score: 0.8722222222222222\n",
      "Iteration: 160\t Score: 0.8722222222222222\n",
      "Iteration: 165\t Score: 0.8222222222222222\n",
      "Iteration: 170\t Score: 0.8666666666666667\n",
      "Iteration: 175\t Score: 0.8777777777777778\n",
      "Iteration: 180\t Score: 0.8388888888888889\n",
      "Iteration: 185\t Score: 0.8555555555555555\n",
      "Iteration: 190\t Score: 0.8611111111111112\n",
      "Iteration: 195\t Score: 0.8611111111111112\n",
      "Iteration: 200\t Score: 0.85\n",
      "Iteration: 205\t Score: 0.85\n",
      "Iteration: 210\t Score: 0.9\n",
      "Iteration: 215\t Score: 0.8722222222222222\n",
      "Iteration: 220\t Score: 0.8666666666666667\n",
      "Iteration: 225\t Score: 0.8666666666666667\n",
      "Iteration: 230\t Score: 0.8666666666666667\n",
      "Iteration: 235\t Score: 0.85\n",
      "Iteration: 240\t Score: 0.8888888888888888\n",
      "Iteration: 245\t Score: 0.8888888888888888\n",
      "Iteration: 250\t Score: 0.8722222222222222\n",
      "Iteration: 255\t Score: 0.8722222222222222\n",
      "Iteration: 260\t Score: 0.8888888888888888\n",
      "Iteration: 265\t Score: 0.8888888888888888\n",
      "Iteration: 270\t Score: 0.8833333333333333\n",
      "Iteration: 275\t Score: 0.8722222222222222\n",
      "Iteration: 280\t Score: 0.8555555555555555\n",
      "Iteration: 285\t Score: 0.8611111111111112\n",
      "Iteration: 290\t Score: 0.8611111111111112\n",
      "Iteration: 295\t Score: 0.9055555555555556\n",
      "Iteration: 300\t Score: 0.8666666666666667\n",
      "Iteration: 305\t Score: 0.8888888888888888\n",
      "Iteration: 310\t Score: 0.8944444444444445\n",
      "Iteration: 315\t Score: 0.8777777777777778\n",
      "Iteration: 320\t Score: 0.8777777777777778\n",
      "Iteration: 325\t Score: 0.8777777777777778\n",
      "Iteration: 330\t Score: 0.9222222222222223\n",
      "Iteration: 335\t Score: 0.9222222222222223\n",
      "Iteration: 340\t Score: 0.9222222222222223\n",
      "Iteration: 345\t Score: 0.8833333333333333\n",
      "Iteration: 350\t Score: 0.8833333333333333\n",
      "Iteration: 355\t Score: 0.8833333333333333\n",
      "Iteration: 360\t Score: 0.8833333333333333\n",
      "Iteration: 365\t Score: 0.8888888888888888\n",
      "Iteration: 370\t Score: 0.8888888888888888\n",
      "Iteration: 375\t Score: 0.8888888888888888\n",
      "Iteration: 380\t Score: 0.9277777777777778\n",
      "Iteration: 385\t Score: 0.9277777777777778\n",
      "Iteration: 390\t Score: 0.9111111111111111\n",
      "Iteration: 395\t Score: 0.9111111111111111\n",
      "Iteration: 400\t Score: 0.8944444444444445\n",
      "Iteration: 405\t Score: 0.9\n",
      "Iteration: 410\t Score: 0.8833333333333333\n",
      "Iteration: 415\t Score: 0.8833333333333333\n",
      "Iteration: 420\t Score: 0.8777777777777778\n",
      "Iteration: 425\t Score: 0.8833333333333333\n",
      "Iteration: 430\t Score: 0.8833333333333333\n",
      "Iteration: 435\t Score: 0.9111111111111111\n",
      "Iteration: 440\t Score: 0.9\n",
      "Iteration: 445\t Score: 0.9222222222222223\n",
      "Iteration: 450\t Score: 0.8722222222222222\n",
      "Iteration: 455\t Score: 0.8722222222222222\n",
      "Iteration: 460\t Score: 0.8722222222222222\n",
      "Iteration: 465\t Score: 0.8722222222222222\n",
      "Iteration: 470\t Score: 0.8722222222222222\n",
      "Iteration: 475\t Score: 0.8722222222222222\n",
      "Iteration: 480\t Score: 0.8722222222222222\n",
      "Iteration: 485\t Score: 0.8888888888888888\n",
      "Iteration: 490\t Score: 0.9333333333333333\n",
      "Iteration: 495\t Score: 0.9222222222222223\n",
      "Iteration: 500\t Score: 0.9222222222222223\n",
      "Iteration: 505\t Score: 0.9222222222222223\n",
      "Iteration: 510\t Score: 0.9222222222222223\n",
      "Iteration: 515\t Score: 0.9222222222222223\n",
      "Iteration: 520\t Score: 0.9333333333333333\n",
      "Iteration: 525\t Score: 0.9333333333333333\n",
      "Iteration: 530\t Score: 0.9222222222222223\n",
      "Iteration: 535\t Score: 0.9222222222222223\n",
      "Iteration: 540\t Score: 0.9\n",
      "Iteration: 545\t Score: 0.9\n",
      "Iteration: 550\t Score: 0.9055555555555556\n",
      "Iteration: 555\t Score: 0.9055555555555556\n",
      "Iteration: 560\t Score: 0.9166666666666666\n",
      "Iteration: 565\t Score: 0.9166666666666666\n",
      "Iteration: 570\t Score: 0.9333333333333333\n",
      "Iteration: 575\t Score: 0.9111111111111111\n",
      "Iteration: 580\t Score: 0.8944444444444445\n",
      "Iteration: 585\t Score: 0.8944444444444445\n",
      "Iteration: 590\t Score: 0.8944444444444445\n",
      "Iteration: 595\t Score: 0.8944444444444445\n",
      "Iteration: 600\t Score: 0.8944444444444445\n",
      "Iteration: 605\t Score: 0.8944444444444445\n",
      "Iteration: 610\t Score: 0.8944444444444445\n",
      "Iteration: 615\t Score: 0.8944444444444445\n",
      "Iteration: 620\t Score: 0.8944444444444445\n",
      "Iteration: 625\t Score: 0.8944444444444445\n",
      "Iteration: 630\t Score: 0.9222222222222223\n",
      "Iteration: 635\t Score: 0.9277777777777778\n",
      "Iteration: 640\t Score: 0.9277777777777778\n",
      "Iteration: 645\t Score: 0.9277777777777778\n",
      "Iteration: 650\t Score: 0.9333333333333333\n",
      "Iteration: 655\t Score: 0.9333333333333333\n",
      "Iteration: 660\t Score: 0.9333333333333333\n",
      "Iteration: 665\t Score: 0.9333333333333333\n",
      "Iteration: 670\t Score: 0.9277777777777778\n",
      "Iteration: 675\t Score: 0.9166666666666666\n",
      "Iteration: 680\t Score: 0.9\n",
      "Iteration: 685\t Score: 0.9166666666666666\n",
      "Iteration: 690\t Score: 0.9111111111111111\n",
      "Iteration: 695\t Score: 0.9111111111111111\n",
      "Iteration: 700\t Score: 0.9111111111111111\n",
      "Iteration: 705\t Score: 0.9111111111111111\n",
      "Iteration: 710\t Score: 0.9222222222222223\n",
      "Iteration: 715\t Score: 0.9333333333333333\n",
      "Iteration: 720\t Score: 0.9333333333333333\n",
      "Iteration: 725\t Score: 0.9388888888888889\n",
      "Iteration: 730\t Score: 0.9388888888888889\n",
      "Iteration: 735\t Score: 0.9\n",
      "Iteration: 740\t Score: 0.9\n",
      "Iteration: 745\t Score: 0.9166666666666666\n",
      "Iteration: 750\t Score: 0.9166666666666666\n",
      "Iteration: 755\t Score: 0.9166666666666666\n",
      "Iteration: 760\t Score: 0.9166666666666666\n",
      "Iteration: 765\t Score: 0.9166666666666666\n",
      "Iteration: 770\t Score: 0.9166666666666666\n",
      "Iteration: 775\t Score: 0.9111111111111111\n",
      "Iteration: 780\t Score: 0.9055555555555556\n",
      "Iteration: 785\t Score: 0.9388888888888889\n",
      "Iteration: 790\t Score: 0.9166666666666666\n",
      "Iteration: 795\t Score: 0.9333333333333333\n",
      "Iteration: 800\t Score: 0.9111111111111111\n",
      "Iteration: 805\t Score: 0.9111111111111111\n",
      "Iteration: 810\t Score: 0.9333333333333333\n",
      "Iteration: 815\t Score: 0.9166666666666666\n",
      "Iteration: 820\t Score: 0.9166666666666666\n",
      "Iteration: 825\t Score: 0.9166666666666666\n",
      "Iteration: 830\t Score: 0.9166666666666666\n",
      "Iteration: 835\t Score: 0.9166666666666666\n",
      "Iteration: 840\t Score: 0.9166666666666666\n",
      "Iteration: 845\t Score: 0.9444444444444444\n",
      "Iteration: 850\t Score: 0.9444444444444444\n",
      "Iteration: 855\t Score: 0.9055555555555556\n",
      "Iteration: 860\t Score: 0.9055555555555556\n",
      "Iteration: 865\t Score: 0.9388888888888889\n",
      "Iteration: 870\t Score: 0.9388888888888889\n",
      "Iteration: 875\t Score: 0.9277777777777778\n",
      "Iteration: 880\t Score: 0.9277777777777778\n",
      "Iteration: 885\t Score: 0.9277777777777778\n",
      "Iteration: 890\t Score: 0.9277777777777778\n",
      "Iteration: 895\t Score: 0.9277777777777778\n",
      "Iteration: 900\t Score: 0.9277777777777778\n",
      "Iteration: 905\t Score: 0.9111111111111111\n",
      "Iteration: 910\t Score: 0.9388888888888889\n",
      "Iteration: 915\t Score: 0.9388888888888889\n",
      "Iteration: 920\t Score: 0.9277777777777778\n",
      "Iteration: 925\t Score: 0.9333333333333333\n",
      "Iteration: 930\t Score: 0.9333333333333333\n",
      "Iteration: 935\t Score: 0.9333333333333333\n",
      "Iteration: 940\t Score: 0.9444444444444444\n",
      "Iteration: 945\t Score: 0.9444444444444444\n",
      "FINAL Iteration: 950\t Score: 0.95\t New Samples Taken: 181\n"
     ]
    }
   ],
   "source": [
    "stream_list = [(stream[x][i][None, :], stream[y][i][None]) for i in range(stream[x].shape[0])]\n",
    "stream_iter = iter(stream_list)\n",
    "\n",
    "num_iters = 0\n",
    "num_samples_taken = 0\n",
    "score = learner.score(x_val, y_val)\n",
    "while score < 0.95 and num_iters < len(stream_list) - 6:\n",
    "    print(f\"Iteration: {num_iters}\\t Score: {score}\")\n",
    "    for i in range(5):\n",
    "        num_iters += 1\n",
    "        inp, target = next(stream_iter)\n",
    "        if learner.query(inp):\n",
    "            num_samples_taken += 1\n",
    "            learner.teach(inp, target)\n",
    "    score = learner.score(x_val, y_val)\n",
    "print(f\"FINAL Iteration: {num_iters}\\t Score: {score}\\t New Samples Taken: {num_samples_taken}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8,\n",
       " 0.8777777777777778,\n",
       " 0.9111111111111111,\n",
       " 0.9222222222222223,\n",
       " 0.9444444444444444]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[learner.models[i].score(x_val, y_val) for i in range(len(learner.models))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Measure : KL-Divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 5., 5.],\n",
       "       [5., 5., 5.]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([np.ones((2,3)) for i in range(5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "models = [RandomForestClassifier(n_estimators=8), \n",
    "         RandomForestClassifier(n_estimators=12), \n",
    "         RandomForestClassifier(n_estimators=16),\n",
    "         RandomForestClassifier(n_estimators=20),\n",
    "         RandomForestClassifier(n_estimators=24)]\n",
    "strategy = \"committee\"\n",
    "committee_measure = \"kl divergence\"\n",
    "\n",
    "learner = ActiveLearner(models, strategy=strategy, committee_measure=committee_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learner.teach(train[x], train[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48333333333333334"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.score(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\t Score: 0.48333333333333334\n",
      "Iteration: 5\t Score: 0.4888888888888889\n",
      "Iteration: 10\t Score: 0.5555555555555556\n",
      "Iteration: 15\t Score: 0.5611111111111111\n",
      "Iteration: 20\t Score: 0.5611111111111111\n",
      "Iteration: 25\t Score: 0.6666666666666666\n",
      "Iteration: 30\t Score: 0.6055555555555555\n",
      "Iteration: 35\t Score: 0.6833333333333333\n",
      "Iteration: 40\t Score: 0.6777777777777778\n",
      "Iteration: 45\t Score: 0.7333333333333333\n",
      "Iteration: 50\t Score: 0.7\n",
      "Iteration: 55\t Score: 0.7166666666666667\n",
      "Iteration: 60\t Score: 0.7388888888888889\n",
      "Iteration: 65\t Score: 0.6833333333333333\n",
      "Iteration: 70\t Score: 0.6888888888888889\n",
      "Iteration: 75\t Score: 0.7222222222222222\n",
      "Iteration: 80\t Score: 0.7555555555555555\n",
      "Iteration: 85\t Score: 0.7555555555555555\n",
      "Iteration: 90\t Score: 0.8111111111111111\n",
      "Iteration: 95\t Score: 0.7555555555555555\n",
      "Iteration: 100\t Score: 0.8\n",
      "Iteration: 105\t Score: 0.7777777777777778\n",
      "Iteration: 110\t Score: 0.7833333333333333\n",
      "Iteration: 115\t Score: 0.7888888888888889\n",
      "Iteration: 120\t Score: 0.7833333333333333\n",
      "Iteration: 125\t Score: 0.8388888888888889\n",
      "Iteration: 130\t Score: 0.8\n",
      "Iteration: 135\t Score: 0.7722222222222223\n",
      "Iteration: 140\t Score: 0.8111111111111111\n",
      "Iteration: 145\t Score: 0.8166666666666667\n",
      "Iteration: 150\t Score: 0.8333333333333334\n",
      "Iteration: 155\t Score: 0.7888888888888889\n",
      "Iteration: 160\t Score: 0.7888888888888889\n",
      "Iteration: 165\t Score: 0.7888888888888889\n",
      "Iteration: 170\t Score: 0.85\n",
      "Iteration: 175\t Score: 0.8277777777777777\n",
      "Iteration: 180\t Score: 0.8388888888888889\n",
      "Iteration: 185\t Score: 0.8388888888888889\n",
      "Iteration: 190\t Score: 0.8333333333333334\n",
      "Iteration: 195\t Score: 0.8055555555555556\n",
      "Iteration: 200\t Score: 0.8222222222222222\n",
      "Iteration: 205\t Score: 0.8222222222222222\n",
      "Iteration: 210\t Score: 0.8444444444444444\n",
      "Iteration: 215\t Score: 0.8444444444444444\n",
      "Iteration: 220\t Score: 0.85\n",
      "Iteration: 225\t Score: 0.8555555555555555\n",
      "Iteration: 230\t Score: 0.8722222222222222\n",
      "Iteration: 235\t Score: 0.8555555555555555\n",
      "Iteration: 240\t Score: 0.8444444444444444\n",
      "Iteration: 245\t Score: 0.8222222222222222\n",
      "Iteration: 250\t Score: 0.8444444444444444\n",
      "Iteration: 255\t Score: 0.8611111111111112\n",
      "Iteration: 260\t Score: 0.8611111111111112\n",
      "Iteration: 265\t Score: 0.8611111111111112\n",
      "Iteration: 270\t Score: 0.8777777777777778\n",
      "Iteration: 275\t Score: 0.85\n",
      "Iteration: 280\t Score: 0.8166666666666667\n",
      "Iteration: 285\t Score: 0.8333333333333334\n",
      "Iteration: 290\t Score: 0.8444444444444444\n",
      "Iteration: 295\t Score: 0.8777777777777778\n",
      "Iteration: 300\t Score: 0.8777777777777778\n",
      "Iteration: 305\t Score: 0.85\n",
      "Iteration: 310\t Score: 0.8555555555555555\n",
      "Iteration: 315\t Score: 0.8555555555555555\n",
      "Iteration: 320\t Score: 0.85\n",
      "Iteration: 325\t Score: 0.85\n",
      "Iteration: 330\t Score: 0.8444444444444444\n",
      "Iteration: 335\t Score: 0.8611111111111112\n",
      "Iteration: 340\t Score: 0.8611111111111112\n",
      "Iteration: 345\t Score: 0.8611111111111112\n",
      "Iteration: 350\t Score: 0.8777777777777778\n",
      "Iteration: 355\t Score: 0.8666666666666667\n",
      "Iteration: 360\t Score: 0.8722222222222222\n",
      "Iteration: 365\t Score: 0.8555555555555555\n",
      "Iteration: 370\t Score: 0.8555555555555555\n",
      "Iteration: 375\t Score: 0.8777777777777778\n",
      "Iteration: 380\t Score: 0.8888888888888888\n",
      "Iteration: 385\t Score: 0.8888888888888888\n",
      "Iteration: 390\t Score: 0.8833333333333333\n",
      "Iteration: 395\t Score: 0.8833333333333333\n",
      "Iteration: 400\t Score: 0.8833333333333333\n",
      "Iteration: 405\t Score: 0.8833333333333333\n",
      "Iteration: 410\t Score: 0.8944444444444445\n",
      "Iteration: 415\t Score: 0.8833333333333333\n",
      "Iteration: 420\t Score: 0.8888888888888888\n",
      "Iteration: 425\t Score: 0.9\n",
      "Iteration: 430\t Score: 0.8722222222222222\n",
      "Iteration: 435\t Score: 0.8888888888888888\n",
      "Iteration: 440\t Score: 0.9055555555555556\n",
      "Iteration: 445\t Score: 0.8888888888888888\n",
      "Iteration: 450\t Score: 0.8777777777777778\n",
      "Iteration: 455\t Score: 0.8833333333333333\n",
      "Iteration: 460\t Score: 0.9222222222222223\n",
      "Iteration: 465\t Score: 0.8777777777777778\n",
      "Iteration: 470\t Score: 0.8777777777777778\n",
      "Iteration: 475\t Score: 0.8888888888888888\n",
      "Iteration: 480\t Score: 0.8888888888888888\n",
      "Iteration: 485\t Score: 0.9\n",
      "Iteration: 490\t Score: 0.8777777777777778\n",
      "Iteration: 495\t Score: 0.8777777777777778\n",
      "Iteration: 500\t Score: 0.9\n",
      "Iteration: 505\t Score: 0.9055555555555556\n",
      "Iteration: 510\t Score: 0.8944444444444445\n",
      "Iteration: 515\t Score: 0.8944444444444445\n",
      "Iteration: 520\t Score: 0.9\n",
      "Iteration: 525\t Score: 0.9\n",
      "Iteration: 530\t Score: 0.9222222222222223\n",
      "Iteration: 535\t Score: 0.9\n",
      "Iteration: 540\t Score: 0.9\n",
      "Iteration: 545\t Score: 0.9111111111111111\n",
      "Iteration: 550\t Score: 0.8944444444444445\n",
      "Iteration: 555\t Score: 0.9055555555555556\n",
      "Iteration: 560\t Score: 0.9055555555555556\n",
      "Iteration: 565\t Score: 0.9\n",
      "Iteration: 570\t Score: 0.9\n",
      "Iteration: 575\t Score: 0.9055555555555556\n",
      "Iteration: 580\t Score: 0.9055555555555556\n",
      "Iteration: 585\t Score: 0.9055555555555556\n",
      "Iteration: 590\t Score: 0.8944444444444445\n",
      "Iteration: 595\t Score: 0.9166666666666666\n",
      "Iteration: 600\t Score: 0.9166666666666666\n",
      "Iteration: 605\t Score: 0.9055555555555556\n",
      "Iteration: 610\t Score: 0.9055555555555556\n",
      "Iteration: 615\t Score: 0.9055555555555556\n",
      "Iteration: 620\t Score: 0.9055555555555556\n",
      "Iteration: 625\t Score: 0.9\n",
      "Iteration: 630\t Score: 0.9055555555555556\n",
      "Iteration: 635\t Score: 0.9277777777777778\n",
      "Iteration: 640\t Score: 0.9277777777777778\n",
      "Iteration: 645\t Score: 0.9055555555555556\n",
      "Iteration: 650\t Score: 0.9166666666666666\n",
      "Iteration: 655\t Score: 0.9055555555555556\n",
      "Iteration: 660\t Score: 0.9166666666666666\n",
      "Iteration: 665\t Score: 0.9166666666666666\n",
      "Iteration: 670\t Score: 0.9111111111111111\n",
      "FINAL Iteration: 675\t Score: 0.9611111111111111\t New Samples Taken: 219\n"
     ]
    }
   ],
   "source": [
    "stream_list = [(stream[x][i][None, :], stream[y][i][None]) for i in range(stream[x].shape[0])]\n",
    "stream_iter = iter(stream_list)\n",
    "\n",
    "num_iters = 0\n",
    "num_samples_taken = 0\n",
    "score = learner.score(x_val, y_val)\n",
    "while score < 0.95 and num_iters < len(stream_list) - 6:\n",
    "    print(f\"Iteration: {num_iters}\\t Score: {score}\")\n",
    "    for i in range(5):\n",
    "        num_iters += 1\n",
    "        inp, target = next(stream_iter)\n",
    "        if learner.query(inp):\n",
    "            num_samples_taken += 1\n",
    "            learner.teach(inp, target)\n",
    "    score = learner.score(x_val, y_val)\n",
    "print(f\"FINAL Iteration: {num_iters}\\t Score: {score}\\t New Samples Taken: {num_samples_taken}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "537px",
    "left": "1193px",
    "right": "20px",
    "top": "120px",
    "width": "227px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
